{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_or_load_pickle, ignore_warnings, ProgressReporter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "ビッグデータとは，コンピュータが速度やメモリ，データの大きすぎといった問題で処理しきれないデータ  \n",
    "- jug\n",
    "    - 長時間に及ぶ計算において，一時的な結果をキャッシュして置いたり，並列計算させたりできる\n",
    "    - タスク: キャッシュを取られ，並列計算される関数．TaskGeneratorデコレータで指定．依存関係のあるタスクは自動的に解決される\n",
    "    - jug executeで実行され，キャッシュディレクトリが生成される\n",
    "- AWS\n",
    "    - 処理能力の高い環境を一時間単位でレンタルできる\n",
    "    - 大規模なマルチコア，GPUなどを使ってjugなどを利用できる\n",
    "- starcluster\n",
    "    - Amazonのマシン作成作業をスクリプトで自動化するためのパッケージ\n",
    "    - Python2.7までしか対応していない．おそらくPython3ではboto3が推奨\n",
    "    - マスターノードと複数のスレーブノードからなるクラスタを作成できる．\n",
    "    - クラスタ内ではjugなどのジョブをキューイングエンジンによって分担して実行できる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現代は，コンピュータの処理速度のペースよりもデータが増えるペースの方が早くなっており，いずれ追いつけなくなる．  \n",
    "ビッグデータの定義は，データが大きすぎるため処理を終えることができないようなデータのこととする．  \n",
    "本章の前半では，jugというパッケージを使って中規模のデータを対象にシステムを作成し，以下のようなことを行う．  \n",
    "- 一連の処理をタスクに分割する  \n",
    "- 中間結果をキャッシュする\n",
    "- マルチコアを利用する(グリッド上の複数台コンピュータを含む)\n",
    "\n",
    "本章の後半では，AWSクラウドによるビッグデータの利用方法を見ていく．  \n",
    "また，pythonのパッケージであるstarclusterを使って，AWS上のクラスタを操作する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ビッグデータ入門\n",
    "ビッグデータとは，データの増加するスピードが速すぎたりメモリに入りきらなかったりして処理しきれないデータを指す．  \n",
    "本章の前半では，マルチコア(1台もしくは複数台のマシン)を使って，計算を高速化する方法を学ぶ．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jugを使って，一連の処理をタスクに分割する\n",
    "jugはLuis Pedro Coelho(著者の一人)によって開発されているパッケージで，一斉に問題を解くことができる．  \n",
    "- 一時的な結果をディスクやデータベースに保存し，あとから再計算させることができる\n",
    "- マルチコアもしくはクラスタ上の複数台のコンピュータを利用できる．\n",
    "    - キューイングシステムを使うバッチ処理を行う環境で性能を発揮\n",
    "        - Portable Batch System(PBS), Load Sharing Facility(LSF), Oracle Grid Engine(OGE, Sun Grid Engine)などがある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## タスクについて\n",
    "タスクとは，jugで行う処理の構成要素となる関数をさす．  \n",
    "例えば次のような関数がタスクになる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double(x):\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jugを用いることで，これらのタスクは次のように書くことができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jug import Task\n",
    "t1 = Task(double, 3)\n",
    "t2 = Task(double, 642.34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のコードをjugfile.pyという名前で保存し，コマンドライン上でjug executeを実行する．  \n",
    "するとdoubleというタスクが2つ実行された旨が表示され，キャッシュデータの入ったjugfile.jugdataディレクトリが作成される．  \n",
    "再度jug executeを実行すると，すでに計算は行われたのでこれ以上計算する必要はなく，計算が行われない．  \n",
    "<br>\n",
    "ここで純粋関数と一般的な関数に気を付ける．  \n",
    "純粋関数とは単に入力された値を受け取り，結果を返すだけの服地作用のない関数．  \n",
    "一般的な関数はファイルの読み書き，グローバル変数の読み込み，引数の書き換えなど，言語の許可する操作を行う関数．  \n",
    "Haskellなどの関数型言語では，純粋関数と一般関数を区別するシンタックスが用意されている．  \n",
    "jugのタスクは純粋関数である必要はないが，並列処理を行うため実行順序がランダムなので，グローバル変数の読み書きをうまく行えない．  \n",
    "こういったミスを発見するため，jug execute --debug が用意されている．  \n",
    "<br>\n",
    "より自然に，効率よくタスクを生成，実行したい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from jug import TaskGenerator\n",
    "from time import sleep\n",
    "\n",
    "@TaskGenerator\n",
    "def double(x):\n",
    "    sleep(4)\n",
    "    return 2 * x\n",
    "\n",
    "@TaskGenerator\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "@TaskGenerator\n",
    "def print_final_result(oname, value):\n",
    "    with open(oname, 'w') as output:\n",
    "        print(\"Final result:\", value, file=output) # ファイルに出力\n",
    "\n",
    "y = double(2)\n",
    "z = double(y)\n",
    "y2 = double(7)\n",
    "z2 = double(y2)\n",
    "print_final_result('output.txt', add(z, z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jug execute 上のコードが書かれたファイル名 を行うと，先ほどのように実行される．  \n",
    "TaskGeneratorを使うことで，一連のタスクを生成し，マルチコアCPUの恩恵を受けることができる．  \n",
    "同時に，結果同士の依存関係を解決してくれる．  \n",
    "jug execute jug_file_name.pyをバックグラウンドで実行しておけば，jug statusによって今どのタスクがRunningなのかが分かる．  \n",
    "上記では4回doubleを実行しているため，普通なら16秒待つところだが，マルチコアで動作していれば大体8秒程度で完了する．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部分的な結果を再利用する\n",
    "新しい特徴量を追加したい場合を想定する．  \n",
    "全ての特徴量を再計算するのは無駄である．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "@TaskGenerator\n",
    "def hfeature(im):\n",
    "    import mahotas as mh # グローバルモジュールではなく，ローカルに持つ．少しばかりの最適化になる．\n",
    "    im = mh.imread(fname, as_gray=1)\n",
    "    return np.mean(mh.features.haralick(image), 0) # Haralick特徴量\n",
    "\n",
    "@TaskGenerator\n",
    "def new_features(im):\n",
    "    import mahotas as mh # グローバルモジュールではなく，ローカルに持つ\n",
    "    im = mh.imread(fname, as_gray=1)\n",
    "    es = mh.sobel(im, just_filter=1)\n",
    "    return np.array([np.dot(es.ravel(), es.ravel())])\n",
    "\n",
    "import glob\n",
    "filenames = glob.glob(\"./data/ch10/SimpleImageDataset/*.jpg\")\n",
    "hfeatures = np.as_array([hfeature(f) for f in filenames])\n",
    "efeatures = np.as_array([new_features(f) for f in filenames])\n",
    "\n",
    "features = Task(np.hstack, [hfeatures, efeatures])\n",
    "\n",
    "# ... 学習コード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一度jugでhfeaturesを求めて置いた後，efeaturesを追加してもう一度実行すると，hfeatureの値はキャッシュデータから読み込まれる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内部で行われていること\n",
    "タスクは引数だけでなく，他のタスクを取ることもできる．  \n",
    "あるタスクがほかのタスクを引数に取れば，その間には依存関係が作られ，子タスクの結果が出るまで親タスクの結果を計算しない．  \n",
    "この依存関係に基づき，各タスクのためのハッシュを再帰的に計算する．  \n",
    "ハッシュとは，そこにたどり着くまでに計算した全作業をエンコードして，数値化したもの．  \n",
    "jug executeは次のような簡単なループ処理によって行われている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for t in alltasks:\n",
    "    if t.has_not_run() and not backend_has_value(t.hash()):\n",
    "        value = t.execute()\n",
    "        save_to_backend(value, key=t.hash())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際のループ処理では，並列処理のロック問題のため，より複雑になる．  \n",
    "ここで生成されるキャッシュデータがjugfile.jugdata/に書き込まれる．  \n",
    "ファイルだけでなく，Redisデータベースに書き込むことも可能である．  \n",
    "<br>\n",
    "タスクを少しでも変更すれば，そのハッシュ値は変更され，再度計算される．  \n",
    "そのタスクに依存するタスクも，同様にハッシュが計算されるため，再計算される．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ分析のためにjugを使用する\n",
    "jugは中規模のデータ分析を行うのにとりわけ向いている．  \n",
    "前処理部分は計算済みで，特徴量を計算する部分だけを変更した場合，前処理部分の計算を避けることができる．  \n",
    "また，jugはnumpy配列に特に最適化されており，他のライブラリとうまく連携することができる．  \n",
    "<br>\n",
    "ここでは，もう一度10章でやった画像の特徴量取得に関する計算を例に挙げ，jugによる処理を行ってみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from jug import TaskGenerator\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "@TaskGenerator\n",
    "def hfeatures(fname):\n",
    "    import mahotas as mh\n",
    "    import numpy as np\n",
    "    im = mh.imread(fname, as_grey=1)\n",
    "    im = mh.stretch(im)\n",
    "    h = mh.features.haralick(im)\n",
    "    return np.hstack([h.ptp(0), h.mean()])\n",
    "\n",
    "@TaskGenerator\n",
    "def label_for(f):\n",
    "    return f[:-(3+1+2)] # 3はjpg, 1はドット，2は数字の文字数\n",
    "\n",
    "@TaskGenerator\n",
    "def perform_cross_validation(features, labels):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    return cross_val_score(LogisticRegression(), features, labels, cv=5).mean()\n",
    "\n",
    "@TaskGenerator\n",
    "def write_result(ofname, value):\n",
    "    with open(ofname, 'w') as out:\n",
    "        print(\"Result is:\", value, file=out)\n",
    "\n",
    "filenames = glob.glob(\"../ch10/SimpleImageDataset/*.jpg\")\n",
    "\n",
    "# TaskGeneratorはどのような関数にも使用することができる．\n",
    "as_array = TaskGenerator(np.array)\n",
    "\n",
    "features = as_array([hfeatures(f) for f in filenames])\n",
    "\n",
    "labels = list(map(label_for, filenames)) # こういうとこでつまづいてもそれまで計算していた値がキャッシュされているから大丈夫！\n",
    "res = perform_cross_validation(features, labels)\n",
    "\n",
    "write_result('output_images.txt', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上のコードを.pyファイルで保存し，jug executeすると計算が行われ，結果がoutput_images.txtに出力される．  \n",
    "TaskGeneratorによるわずかな手間がかかるが，より便利にjugを使うためには必要になる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下にjugのその他の興味深いコマンドについて示す． \n",
    "- jug invalidate function_name: function_nameの関数の結果が不適切であるとみなし，その結果に依存する関数を含めて再計算する\n",
    "- jug status --cache: jug statusの高速化，さらに --clearを追記することでキャッシュを削除しjugfile.pyの変更判定を行う\n",
    "- jug cleanup: 余分なキャッシュファイルをすべて削除\n",
    "\n",
    "他にも拡張機能はたくさんある．内部で計算されたデータを確認するような機能もある．  \n",
    "jugのドキュメントの[barriers](https://readthedocs.org/)のページを参照．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSを使用する\n",
    "AWSでは処理能力の高い環境を一時間単位でレンタルできる．  \n",
    "ここでは，仮想マシンとディスクスペースを提供しているEC2(Elastic Compute Cluster)を利用する．  \n",
    "EC2には3つのモードがある．  \n",
    "- リザーブドモード: 前払い制で単位時間のコストが安い\n",
    "- 単位時間のレートを固定するモード\n",
    "- 全体の状況に応じてレートを変動するモード\n",
    "\n",
    "テスト用には「Free tier(無料版)」でシングルマシンを使える．  \n",
    "CPUは遅いが，インタフェースの使い方に慣れたり，色んな実験を行うのに適している．  \n",
    "<br>\n",
    "EC2にはコストに応じて様々なマシンがある．  \n",
    "シングルコアから大容量RAMを備えたマルチコア，GPUも．  \n",
    "LinuxサーバかWindowsサーバを選べるが，Linuxサーバの方が若干安い．  \n",
    "<br>\n",
    "操作や設定スクリプトの記述はブラウザのUIコンソールから行えるが，プログラムのインタフェースの方が比較的変更が少ない．  \n",
    "<br>\n",
    "AWSでは，ユーザ名のことを「アクセスキー」，パスワードのことを「シークレットキー」と呼び，これらでログインを行う．  \n",
    "アクセスキー，シークレットキーのペアはいつでもいくつでも?作ることができ，それぞれに異なる権限を与えることができる．  \n",
    "<br>\n",
    "サーバのリージョンは物理的に近いリージョンを選んだ方がデータの送受信が早い．  \n",
    "また，海外のリージョンを使うときには個人情報に気を付ける．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初めてのマシンを作成する\n",
    "無理に有料マシンを使うことはない．  \n",
    "まずは[AWS](https://us-east-2.console.aws.amazon.com/console/home?nc2=h_ct&region=us-east-2&src=header-signin#)にアクセスし，サインアップもしくはログインを済ませる．  \n",
    "\n",
    "- EC2を選択\n",
    "- 右上メニューからまずリージョンを選択(ここではアジアパシフィック(東京))\n",
    "- 適当なLinuxサーバを選択．Pythonなどがすでに入っているバージョンがあるが，ない方を選択\n",
    "- 無料枠，最小構成のt2.microを選択\n",
    "- 「確認」まで進み，「起動」をクリック\n",
    "- 「新しいキーペアの作成」を行う．ここでは「awskeys」というキーペア名にし，キーペアをダウンロードする．\n",
    "    - ダウンロードされるpemファイルは大切に保存すること！\n",
    "- 「インスタンスを作成」する．(AWSのサーバはインスタンスと呼ばれる)\n",
    "- インスタンスリストページでインスタンスのステータスが緑色の「runnning」になるまで待つ\n",
    "- 作成したインスタンスを選択した状態で，「接続」ボタンを押すと，ssh接続コマンドの例が出てくる．\n",
    "  - Mac\n",
    "    - awskeys.pemのパーミッションを400に変える．そうでないとBad Permissionでエラーになる．\n",
    "    - コマンドの例をawskeys.pemがあるディレクトリで実行すると接続\n",
    "    - ec2-userのところは，メインページの右上に表示されている名前\n",
    "  - Windows(https://dev.classmethod.jp/cloud/aws/first-login-to-ec2-linux/)\n",
    "    - Windowsではpemのパーミッションの都合でログインできないので，TeratermやPuTTYを使ってログインする．\n",
    "    - Teratermでは，ホスト名にパブリックDNSをコピペしてOK\n",
    "    - ユーザ名には初期ユーザ名(多分ec2-user)，パスフレーズは空欄\n",
    "    - RSA/DSA/ECDSA...鍵を使うのところを選択し，秘密鍵を選択．すべてのファイルを表示で見える．  \n",
    "    - OKでログイン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PythonパッケージをAmazon Linuxにインストールする\n",
    "デフォルトだとPython2系なのでPython3.7を入れ，他にも必要な物をインストールする  \n",
    "``` bash\n",
    "> sudo yum -y install python3* gcc-c++ git libpng* libtiff*\n",
    "> python3\n",
    "> sudo pip3 install numpy scipy matplotlib scikit-learn jug mahotas imread\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラウド上でjugを実行する\n",
    "gitで画像ファイルを含むプロジェクトフォルダを好きなところに置く\n",
    "```\n",
    "git clone https://github.com/luispedro/BuildingMachineLearningSystemsWithPython\n",
    "```\n",
    "SimpleImateDatasetにアクセスできるよう先ほどのコードを変更し，viでコピペ．  \n",
    "後はjug execute & でバックグラウンド動作させ，jug statusで見守る\n",
    "<br>\n",
    "結果が出るまでそこそこ待つ．  \n",
    "より強力なインスタンスを使うには\n",
    "- インスタンスを一旦停止\n",
    "- change instance type(例えばextra largeインスタンスは当時0.58$/h かかっていた)\n",
    "- マシンを起動\n",
    "- 接続情報が変更されているので「接続」を押してアドレスを確認\n",
    "    - Elastic IPによって固定アドレスが手に入る．そんなに高くない．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## starclusterでクラスタの生成を自動化する\n",
    "starcluster: Amazonのマシン作成作業をスクリプトで自動化するためのパッケージ  \n",
    "しかしPython2.7までしか対応していないので詳細は書かない．  \n",
    "恐らくPython3ではboto3を利用するが，一応どんなことができるかだけ書いていく．\n",
    "\n",
    "``` bash\n",
    "> pip install starcluster # 失敗する\n",
    "```\n",
    "\n",
    "- starcluster help: config ファイルを作成\n",
    "    - AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEYを設定\n",
    "    - 16個のマシン(ノード)からなるクラスタ，smallclusterを定義．さらにマスターノードが作成されるので17台のマシンになる\n",
    "    - イメージ(どのOSか，どのソフトウェアが入っているか，といった情報が入っている初期ディスク)を指定することもできる\n",
    "- starcluster createkey mykey -o .ssh/mykey.rsa: sshキーを作成\n",
    "- starcluster start mycluster: クラスタを生成\n",
    "\n",
    "ジョブ用のキューイングエンジンが準備されているので，これらのノードを使ってバッチ処理ができる．  \n",
    "- マスターノードにログイン\n",
    "    - starcluster sshmaster mycluster\n",
    "- マスターノードでスクリプトを準備\n",
    "    - #!/usr/bin/env bash\n",
    "    - jug execute jugfile.py\n",
    "    - というスクリプトファイルrun-jugfile.shと共に用意しておく．このshファイルには実行権限を与える．\n",
    "- ジョブをキューに送る．jugはもちろん，どんなUnixコマンドでも使える．\n",
    "    - For c in 'seq 16'; do qsub run-jugfile.sh; done\n",
    "    - 16個のジョブを作成し，jugを実行\n",
    "- ジョブの完了を待つ\n",
    "    - マスターノードではjug statusを使える\n",
    "- マスターノードで結果を読む．\n",
    "    - この時点ですべてのスレーブノードを停止させることもできる．\n",
    "- やることが終わったら全ノードを停止\n",
    "    - starcluster terminate mycluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
