{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "企業の製品発売やプレスリリースの反応をチェックするのに，ツイッターなどの文章から感情分析(sentiment classification)を行いたい．  \n",
    "これは意見マイニング(opinion mining)とも呼ばれ，研究開発が勧められている．  \n",
    "前章のクラス分類の知識も応用して，自前で感情分類器を作る．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本章のロードマップ\n",
    "Twitterは文字数が短いため，特別な表記法や略語などが用いられる．  \n",
    "パラグラフごとに感情に関する情報を集めて，その結果から文書全体の感情分析を行いたいが，できない．  \n",
    "ここでは最先端の感情分類器までは踏み込まず，以下の3つのことに取り組む\n",
    "- ナイーブベイズという分類手法を学ぶ\n",
    "- 品詞タグ付け(Part-of-Speech tagging)について学ぶ\n",
    "- scikit-learnのツールの使い方を学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ツイートデータを取得する\n",
    "ツイートとそれに対応するラベル(意見なし,ポジティブ，ネガティブ，無感情)一式が欲しい．  \n",
    "Niek Sandersらによって5000以上のツイートに対して手作業でラベル付けが行われたコーパスを使用する．  \n",
    "install.pyによってTwitterのサーバとやりとりしてデータをダウンロードできる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはinstall.pyをコマンドラインで実行し，dataディレクトリにTweetとラベルのデータをcorpus.csvというファイル名で保存する．  \n",
    "その後，util.pyにあるload_sanders_data()によってデータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ch06.utils import load_sanders_data()\n",
    "X, Y = load_sanders_data()\n",
    "classes = np.unique(Y) # 全ラベルの種類を取得\n",
    "for c in classes:\n",
    "    print(\"#%s: %i\" % (c, sum(Y == c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以降では，意見なし(irrelevant)と感情なし(neutral)を同じものとして扱う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ナイーブベイズ分類器の紹介\n",
    "ナイーブベイズはもっとも洗練された機械学習アルゴリズムの一つと言える．  \n",
    "出力と関係ない特徴量にロバスト，つまり無関係な特徴量をうまく無視する．  \n",
    "学習，予測は高速で，メモリを必要としない．  \n",
    "ナイーブと呼ばれるのは，全ての特徴量が互いに独立である，という過程が必要であるから．  \n",
    "実際にはその過程が成立するのは稀であるがたとえそれが成立しなくても優れた性能を示すことが多い．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マークダウンの左寄せが効かないのでHTMLで無理やり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>td, th{text-align: left !important}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>td, th{text-align: left !important}</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベイズ定理入門\n",
    "ナイーブベイズ分類器が行なっているのは，クラスを分類するためにどの特徴量が証拠となるかということを追跡すること．  \n",
    "ここでは，次の変数を例として使用する．  \n",
    "\n",
    "|変数|取りうる値|意味|\n",
    "| :- | :- | :- |\n",
    "|C|\"pos\", \"neg\"|ツイートが属するクラス(ポジティブ，ネガティブ)|\n",
    "|F1|Int(>=0)|ツイートで「awesome」という単語が用いられた回数|\n",
    "|F2|Int(>=0)|ツイートで「crazy」という単語が用いられた回数|\n",
    "\n",
    "ナイーブベイズでは，あるツイートについて，F1とF2がわかっている時そのツイートがクラスCに属する確率を求めている．  \n",
    "この確率関数は$P(C | F_1, F_2)$と書くことができる．  \n",
    "この確率は直接推定できないので，ベイズの定理を用いて式を変形する．  \n",
    "ベイズの定理を以下に示す．  \n",
    "$$ P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B) $$\n",
    "この式を使うと，  \n",
    "$$ P(F_1, F_2) \\cdot P(C | F_1, F_2) = P(C) \\cdot P(F_1, F_2 | C) $$\n",
    "これを変形し，左辺に$ P(C | F_1, F_2) $ がくるようにすると\n",
    "$$ P(C | F_1, F_2) = \\frac{P(C) \\cdot P(F_1, F_2 | C)}{P(F_1, F_2)} $$\n",
    "これは，次のように言い換えられる．  \n",
    "- posterior: 事後確率, $P(C | F_1, F_2)$, $F_1$と$F_2$がわかっているとき，そのデータがクラス$C$に属する確率\n",
    "- prior: 事前確率, $P(C)$, データについて何も情報がない場合にそのデータがクラス$C$に属する確率\n",
    "- likelihood: 尤度, $P(F_1, F_2 | C)$, あるデータがクラス$C$に属することがわかっている場合，特徴量がその$F_1，F_2$である確率\n",
    "- evidence: 証拠, $P(F_1, F_2)$, 特徴量がその$F_1$と$F_2$をとる確率, 該当する特徴量が全体に占める割合を計算して求める\n",
    "\n",
    "という言葉を使って，\n",
    "$$ posterior = \\frac{prior \\cdot likelihood}{evidence} $$\n",
    "\n",
    "likelihoodを求めるのは少し考える必要がある．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ナイーブにする\n",
    "確率理論($P(A, B) = P(B) \\cdot P(A | B) $)から次の式が成り立つ\n",
    "$$ P(F_1, F_2 | C) = P(F_1 | C) \\cdot P(F_2 | C, F_1)$$\n",
    "この式は，難しい問題$P(F_1, F_2 | C)$を別の難しい問題$P(F_2 | C, F_1)$に変換したにすぎない．  \n",
    "<br>\n",
    "ここで，$F_1$と$F_2$が独立であると仮定(ナイーブ)すると，$P(F_2 | C, F_1)$を$P(F_2 | C)$とかけるため，次のように書き直すことができる．  \n",
    "$$ P(F_1, F_2 | C) = P(F_1 | C) \\cdot P(F_2 | C)$$\n",
    "<br>\n",
    "これを合わせると，次の有用な式を得られる．  \n",
    "$$ P(C | F_1, F_2) = \\frac{P(C) \\cdot P(F_1 | C) \\cdot P(F_2 | C)}{P(F_1, F_2)} $$\n",
    "<br>\n",
    "独立の過程は都合的なもので理論的には正しくないが，現実のアプリケーションでは優れた結果になることが多くあるのが興味深い．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ナイーブベイズを用いて分類を行う\n",
    "新しいツイートが与えられた時に行うことは，単純に次の確率を計算することである．  \n",
    "$$ P(C = \"pos\" | F_1, F_2) = \\frac{P(C=\"pos\") \\cdot P(F_1 | C=\"pos\") \\cdot P(F_2 | C=\"pos\")}{P(F_1, F_2)} $$\n",
    "$$ P(C = \"neg\" | F_1, F_2) = \\frac{P(C=\"neg\") \\cdot P(F_1 | C=\"neg\") \\cdot P(F_2 | C=\"neg\")}{P(F_1, F_2)} $$\n",
    "これらのうち，確率の大きい方を選ぶため，同じ式である分母は無視できる．  \n",
    "この計算では，実際の確率には興味がなく，どちらのクラスの方があり得るか，ということに興味がある．  \n",
    "このことが，ナイーブベイズのロバスト性を高めている理由になっている．  \n",
    "<br>\n",
    "以上を一般化すると，次の式によってツイートを分類できる．  \n",
    "$$ C_{best} = \\arg \\max_{c \\in C} P(C=c) \\cdot P(F_1 | C=c) \\cdot P(F_2 | C=c) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際の例を使って計算を行なってみる．  \n",
    "次のようなラベル付きデータが与えられているとする．  \n",
    "\n",
    "|ツイート|クラス|\n",
    "|:--|:--|\n",
    "|awesome|pos|\n",
    "|awesome|pos|\n",
    "|awesome crazy|pos|\n",
    "|crazy|pos|\n",
    "|crazy|neg|\n",
    "|crazy|neg|\n",
    "\n",
    "このデータから，事前確率は，  \n",
    "$$ P(C=pos) = \\frac{4}{6} \\approx 0.67 $$\n",
    "$$ P(C=neg) = \\frac{2}{6} \\approx 0.33 $$\n",
    "これは，あるツイートについて，その内容を何も知らない場合は，それはポジティブであると予測した方が良いということ．  \n",
    "<br>\n",
    "次に，各条件付き確率を求めていく．  \n",
    "例えば，クラスがposであるとわかっている時，awesomeが存在する確率は次のように表せる．  \n",
    "$$ P(F_1 > 0 | C=pos) = \\frac{3}{4} = 0.75 $$\n",
    "同様にして，\n",
    "$$ P(F_2 > 0 | C=pos) = 0.5 $$\n",
    "$$ P(F_1 > 0 | C=neg) = 0 $$\n",
    "$$ P(F_2 > 0 | C=neg) = 1 $$\n",
    "<br>\n",
    "ここでは，試しにevidenceも計算し，実際の確率を求めてみる．  \n",
    "$$ P(F_1, F_2) = P(F_1, F_2 | C=pos) \\cdot P(C=pos) + P(F_1, F_2 | C=neg) \\cdot P(C=neg) $$\n",
    "実際には次の値になる．  \n",
    "$$ P(F_1 > 1, F_2 > 1) = 0.22 $$\n",
    "$$ P(F_1 > 1, F_2 > 0) = 0.44 $$\n",
    "$$ P(F_1 > 0, F_2 > 1) = 0.33 $$\n",
    "$$ P(F_1 > 0, F_2 > 0) = 0 $$\n",
    "<br>\n",
    "あとは，新しいツイートから特徴量$F_1$，$F_2$を抽出し，分類器に入力するだけ．  \n",
    "awesome -> P: 0.57, N: 0 -> Positive  \n",
    "crazy -> P: 0.25, N: 1 -> Negative  \n",
    "awesome crazy -> P: 0.76, N: 0 -> Positive  \n",
    "text -> P: ∞, N: ∞ （分母となるevidenceが0) -> 不確定  \n",
    "<br>\n",
    "この不確定な時にはどのように対応すれば良いか？  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新出単語への対応\n",
    "上の例は明らかにデータが足りない．不確定な値も出てしまう．  \n",
    "そこで，出現頻度に1を足すスムージング，(加算スムージング, additive smoothing, ラプラススムージング(Laplace Smoothing))を利用する．  \n",
    "ポリゴンメッシュを滑らかにする画像処理のラプラシアンスムージングとは関係ない．  \n",
    "調整可能な0以上のパラメータ$\\alpha$をタスLidstoneスムージングという手法も存在する．  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
