{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "ノイズの多いテキストデータを良い回答，悪い回答に分類するにはどうすれば良いか？という問題に取り組んだ．  \n",
    "使用したデータはstackoverflowの問答データ．教師データになりそうなのはScore．  \n",
    "以降の分類器はscikit-learnに便利な関数が多数用意されている．  \n",
    "\n",
    "- K近傍法による分類\n",
    "    - 特徴量を増やしたり，Kの値を大きくしてモデルを単純にしても，時間がかかるだけで精度が上がらないことがある．  \n",
    "    - モデルを単純にしても特徴量を改良してもバリアンスが高いので，K近傍法はこのタスクに向かないとわかった．\n",
    "        - バイアス-バリアンストレードオフ\n",
    "            - (エラーの)バイアスが高い->未学習, 訓練誤差もテスト誤差も大きい, データのノイズが多い， 特徴量の設計がマズい\n",
    "            - バリアンスが高い->過学習, 訓練誤差とテスト誤差の差が大きい, モデルが複雑すぎる\n",
    "            - これらはトレードオフであり，最適解を探したい\n",
    "- ロジスティック回帰による分類\n",
    "    - ロジスティック回帰: どんな入力にも白か黒かの確率を返す関数の回帰による最適化\n",
    "        - 要は「オッズ比の対数関数の逆関数に入力する線形式の最適化」\n",
    "        - オッズ比：$P/(1-P)$\n",
    "        - 入力無限領域，出力0~1の確率の形にできる\n",
    "        - 1次式を入力するシグモイド関数とも言える\n",
    "        - バイアス+ 係数 ＊ 特徴量の値 + 係数 ＊ 特徴量の値 + ... をロジスティック回帰の式に入力することでクラスに属する確率を得る\n",
    "        - 正規化パラメータCがある\n",
    "    - 最適なCを選んでも，90NNと同じくらいの精度しか出ない．\n",
    "        - バイアスが大きい\n",
    "    - 悪い回答か良い回答のどちらかがわかれば良いのでは?\n",
    "    - 適合率-再現率曲線(Precision-Recall curve)のAUC(Area Under Curve)がもっとも大きい閾値を求める\n",
    "        - 適合率： $TP / (TP + FP)$ 冤罪を起こさない確率\n",
    "        - 再現率: $ TP / (TP + FN) $ 犯人を逃さない確率\n",
    "        - 適合率と再現率はトレードオフ． 再現率をあげてもどれだけ適合率が下がらないかをグラフでみるのが適合率-再現率曲線\n",
    "    - 結果として，良い回答かどうかを分類する方が，悪い回答かどうかを分類するより高いAUCを出せることがわかった．  \n",
    "    - ロジスティック係数が0に近い特徴量は分類器の精度にあまり影響を与えないので省ける\n",
    "    - このモデルをで保存しておくことで，Webサービスなどでは素早く回答の良し悪しを判別させられる．\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意!!\n",
    "Chapter 5 - Classification - Detecting Poor Answers\n",
    "===================================================\n",
    "\n",
    "The book chapter is based on StackExchange's data blob from August 2012 for the first edition. \n",
    "\n",
    "After publishing the book, StackExchange released the May 2014 version at\n",
    "[https://archive.org/download/stackexchange/stackexchange_archive.torrent](https://archive.org/download/stackexchange/stackexchange_archive.torrent).\n",
    "\n",
    "Note that using the latest version, you will get slightly different results.\n",
    "\n",
    "The code is using pyenchant for spell correction. Pyenchent is only used to increase your pleasure of eperimenting with additional features. It is not used later on the chapter. So, if you find out that your platform poses too big problems to install it (e.g. on 64bit Windows), don't bother."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stackoverflowのようなサイト上での質問への回答が良いものかどうかを投稿前に評価してくれる仕組みを作成したい．  \n",
    "<br>\n",
    "難しいのは，100%の正解率を達成するような方法が存在しないということと，回答の内容が良いかどうかという指標は人によって分かれる，ということ．  \n",
    "この章では，最近傍法→ロジスティック回帰→最終的にどの手法を選択すれば良いか ということについて述べていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 良い回答を分類する\n",
    "ラベルづけをまず行いたい．  \n",
    "- データをどのように表現すべきか?\n",
    "- 分類器はどのようなモデル，または構造にすべきか？\n",
    "\n",
    "ということに気をつけながらラベリングを行なっていく．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの表現方法\n",
    "テキストデータそのものは機械学習アルゴリズムでは扱えないので，有効な特徴量となる数値を我々が自分の手で抽出する必要がある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用する分類器\n",
    "テキストとラベル(ここでは，回答が受理されたかどうか)のペアを使って，分類器を訓練できる．  \n",
    "- ロジスティック回帰\n",
    "- 決定木\n",
    "- SVM\n",
    "- ナイーブベイズ\n",
    "\n",
    "といった分類がある．  \n",
    "これまでは，事例に基づく(instance-based)学習であったが,本章では，モデルベースの手法であるロジスティック回帰を利用する．  \n",
    "ここで，インスタンスベースの手法とは，訓練データとして用いた事例をそのまま覚えて利用する手法．新しい事例に対してはもっとも類似した訓練データの事例を使う．例えば最近傍法など．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データを用意する\n",
    "stackoverflowのデータを利用する．  \n",
    "https://archive.org/details/stackexchange  \n",
    "Download optionsのtorrent?  \n",
    "どうもマジでtorrentで入れないといけないみたい  \n",
    "posts.xmlを使う．  \n",
    "1つのrowタグには1つの質問もしくは回答が含まれる．  \n",
    "属性は以下  \n",
    "- Id: ユニークなID\n",
    "- PostTypeId: 投稿文書の種類，質問なら1, 回答なら2\n",
    "- ParentId: 回答の対象ID,質問にはついていない\n",
    "- CreationDate：投稿日時\n",
    "- Score: 投稿データのスコア\n",
    "- ViewCount: 閲覧数\n",
    "- Body: 投稿内容のHTML\n",
    "- OwnerUserId: 投稿したユーザのID，1のとき，Wikiに関する質問であることを示す\n",
    "- Title: 質問のタイトル，回答にはない\n",
    "- AcceptedAnswerId: 受理された回答のIDを示す．回答にはない\n",
    "- CommentCount: 投稿データに対してコメントされた回数を示す\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験サイクルを早めるためにエータサイズを削減する\n",
    "Creation Dateが2011年以降のものに限定し，600万程度の投稿データに絞る．  \n",
    "ファイルをXML形式から必要な情報を抜き出し，TSVにする．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要な属性の選別\n",
    "ID, PostTypeId, ParentID, CreationDate, Score, Body(プレーンテキストに変換), AcceptedAnswerId(IsAccepted属性を追加)  \n",
    "具体的なパースの詳細はso_xml_to_tsv.py, choose_instance.py, meta.json(文書IDと他のデータの対応辞書)を参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse XML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_posts():\n",
    "    for line in open(\"./data/stack_over_flow_data.tsv\", \"r\"):\n",
    "        post_id, text = line.split(\"\\t\")\n",
    "        yield int(post_id), text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 良い回答を定義する\n",
    "受理された回答が丁寧でわかりやすいかというとそうでもない  \n",
    "相対的なスコアは，1000のスコアをとった回答があるとき，500は悪い回答なのか，という問題がでてくる．  \n",
    "ここでは，スコアが0より大きければ良い回答，0以下であれば悪い回答としてみる．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3c3c4acc46a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_answers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mq\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ParentId'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_answers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meta' is not defined"
     ]
    }
   ],
   "source": [
    "all_answers = [q for q, v in meta.iteritems() if v['ParentId'] != -1]\n",
    "Y = np.asarray([meta[aid]['Score'] > 0 for aid in all_answers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最初の分類器を作成する\n",
    "最近傍法はデータをそのまま学習できる美しい手法であるが，これが欠点となることもある．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k近傍法からスタートする\n",
    "sklearnのツールキットを利用する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2近傍法のインスタンスを生成  \n",
    "試しに使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[1], [2], [3], [4], [5], [6]]\n",
    "train_label = [0, 0, 0, 1, 1, 1]\n",
    "knn.fit(train_data, train_label)\n",
    "print(knn.predict([[1.5]])) # 2次元配列を渡すらしい\n",
    "print(knn.predict([[37]]))\n",
    "print(knn.predict([[3]]))\n",
    "\n",
    "# 結果に対する確率\n",
    "print(knn.predict_proba([[1.5]]))\n",
    "print(knn.predict_proba([[37]]))\n",
    "print(knn.predict_proba([[3.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量について模索する\n",
    "リンクの個数が良い回答を得る特徴量？という仮説"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "code_match = re.compile('<pre>(.*?)</pre>', re.MUTILINE | re.DOTALL)\n",
    "link_match = re.compile('<a href=\"http://.*?\".*?>(.*?)</a>', re.MULTILINE | re.DOTALL)\n",
    "\n",
    "def extract_features_from_body(s):\n",
    "    link_count_in_code = 0\n",
    "    # コード中に存在するリンクをカウントする\n",
    "     for matvch_str in code_match.findall(s):\n",
    "            link_count_in_code += len(link_match.findall(match_str))\n",
    "    return len(link_match.findall(s)) - link_count_in_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTMLの構文解析にはBeautiful soupを使った方がいいんだけどね"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リンクの個数を調べてみると，7割の回答にはリンクがないことがわかる．  \n",
    "これでは良い分類器を作成することはできないが，あえてこの特徴量から分類器を作ってみたい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類器の訓練を行う\n",
    "先ほど定義したように，Y=良い回答かどうか(Scoreが1以上)とし,対応する特徴量としてX＝リンクの数を入れてKNN分類器に入力する  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray([extract_features_from_body(text) for post_id, text in fetch_posts() if post_id in all_answers])\n",
    "knn = neighbors.KNeiborsClassifier() # デフォルトでK＝5．これが良いかはあとで考える\n",
    "knn.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類器の評価を行う\n",
    "テストデータに対して正しく予測した割合（Accuracy)を計算することで評価を行う．  \n",
    "これはknn.score()で求めることができる．  \n",
    "交差検定(データを分割してテストデータとして用い,正解率の平均をとる)は，sklearn.cross_validationのKFoldクラスでできる．  \n",
    "標準偏差もとる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "scores = []\n",
    "cv = KFold(n=len(X), k=10, indices=True)\n",
    "for train, test in cv:\n",
    "    X_train, Y_train = X[train], Y[train]\n",
    "    X_test, Y_test = X[test], Y[test]\n",
    "    clf = neighbors.KNeighborsClassifier()\n",
    "    clf.fit(X, Y)\n",
    "    scores.append(clf.score(X_test, Y_test))\n",
    "\n",
    "print(\"Mean(scores)=%.5f\\tStddev(scores)=%.5f\" % (np.mean(scores, np.std(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果は49%程度でしかなく，コインを投げて予測した方がまだまし，というレベル．  \n",
    "文書中にあるリンクの数は質を計測するための良い指標ではないことがわかった．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## より多くの特徴量をデザインする\n",
    "次は文書中のソースコードの行数を特徴量にしてみる  \n",
    "また，ソースコード以外の単語の数も指標にしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソースコード以外の単語数， ソースコードの行数， リンクの個数を特徴量として返す\n",
    "def extract_features_from_body(s):\n",
    "    num_code_lines = 0\n",
    "    link_count_in_code = 0\n",
    "    code_free_s = s\n",
    "    \n",
    "    # ソースコードを取り除き，その行数を数える\n",
    "    for match_str in code_match.findall(s):\n",
    "        num_code_lines += match_str.count('\\n')\n",
    "        code_free_s = code_match.sub(\"\", code_free_s)\n",
    "        # ソースコードにはリンクが含まれることがあり，その場合はカウントしない\n",
    "        link_count_in_code += len(link_match.findall(match_str))\n",
    "    \n",
    "    links = link_match.findall(s)\n",
    "    link_count = len(links)\n",
    "    link_count -= link_count_in_code\n",
    "    \n",
    "    html_free_s = re.sub(\" +\", \" \", tag_match.sub('', code_free_s)).replace(\"\\n\", \"\")\n",
    "    link_free_s = html_free_s\n",
    "    \n",
    "    # 単語の数をカウントする前にリンクを削除する\n",
    "    for link in links:\n",
    "        if link.lower().startwith(\"http://\"):\n",
    "            link_free_s = link_free_s.replace(link, '')\n",
    "        \n",
    "        num_text_tokens = html_free_s.count(\" \")\n",
    "    \n",
    "    return num_text_tokens, num_code_lines, link_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量の傾向をグラフ化してみると，単語の数はソースコードの行数よりも変化に富んでいることがわかる．  \n",
    "<br>\n",
    "これらの特徴量で正解率を計算してみると，スコアは0.58程度になり，すこしだけ正解率を改善することができた．  \n",
    "しかし，まだまだスコアは低い．  \n",
    "そこで特徴量を他にも増やしてみればいいと思いつくが，うまくは行かない．  \n",
    "<br>\n",
    "原因の一つに，どのパラメータも同じ重みで計算されていることがある．  \n",
    "例えば，リンクの数は1つでもあれば良いが，単語の数は10個も20個もあまり変わりはない．  \n",
    "この考察から，今扱っているデータに対してk近傍法ではうまく分類できない．(? 重みパラメータを与えてやればいいのでは？)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改善案について考える\n",
    "改善策として，以下のようなものがある．  \n",
    "- データを追加する\n",
    "- モデルの複雑さを調整する(kを変化させたり)\n",
    "- 特徴量を修正する(スケール変更，新しい特徴量の追加，不要な特徴量の削除など)\n",
    "- モデルを変更する(kNNは適していない?)\n",
    "\n",
    "これらの方法から手当たり次第にうまくいきそうな方法を探していては時間がかかる．  \n",
    "そこで，情報に基づく決定を行うための「バイアス-バリアンスのトレードオフ(bias-variance tradeoff」を紹介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バイアス-バリアンスのトレードオフ\n",
    "1章でみたように，次元が低すぎると未学習を起こす．この状態をデータに対して「バイアスが大きすぎる」と表現する．  \n",
    "また，次元が大きすぎると過学習を起こし，汎化性に欠ける．この状態をデータに対して「バリアンスが大きすぎる」と表現する．  \n",
    "この2つのトレードオフの間にある最適解を見つけたい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バイアスが大きい場合の対処法\n",
    "つまり，複雑性が低すぎる場合．この場合，\n",
    "- 特徴量を増やす\n",
    "- モデルをより複雑なものにする\n",
    "- モデルを変更する\n",
    "\n",
    "といった対処を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バリアンスが大きい場合の対処法\n",
    "つまり，モデルが複雑すぎ流場合． この場合，\n",
    "- より多くのデータを集める\n",
    "- モデルの複雑さを減らす\n",
    "    - kの値を増加させる(減らすんじゃないらしい)\n",
    "- 特徴量の数を減らす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バイアスは大きい？小さい？\n",
    "まず，データサイズを変化させた時の訓練データの誤差(訓練誤差)とテストデータの誤差(テスト誤差)をプロットする．  \n",
    "バイアスが大きい→データサイズが大きくなるにつれて，訓練誤差とテスト誤差の値は共に大きい値に落ち着く\n",
    "バリアンスが大きい→訓練誤差とテスト誤差の示すグラフの曲線に大きな隔たりがある．  \n",
    "<br>\n",
    "5近傍法において，今回の問題のデータサイズを増加した場合の訓練誤差とテスト誤差をプロットすると，2つの曲線には大きな隔たりがある．  \n",
    "すなわち，これはバリアンスが大きいことが問題になっていることがわかる．  \n",
    "これは特徴量を減らしてみても変わらない．  \n",
    "<br>\n",
    "なので，モデルの複雑性を下げるために，kの値を90まであげてみる．  \n",
    "すると，スコアは0.68程度になり，より良い結果を得られる．  \n",
    "しかし，この場合90個の近傍店を見つける必要があり，かなりの時間がかかる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のタスクにk近傍法を使うことには何かしら問題がある．  \n",
    "- 複雑性を下げようとすると時間がかかる\n",
    "- 文書の数が増えるほど分類にかかる時間が長くなる\n",
    "\n",
    "こういった問題は，インスタンスベースの学習であるために起きることが多い．  \n",
    "そこで，テキスト分類の場面で威力を発揮する，モデルベースのアプローチを紹介する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰を用いる\n",
    "回帰とは言っているが，分類に関する手法である．  \n",
    "テキストベースの分類問題で威力を発揮する．  \n",
    "ロジスティック関数で回帰を行い，その結果から分類をおこなうため，この名前がつけられた．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰の簡単な例\n",
    "データセットを人工的に作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ones = [random.uniform(1, 14) for i in range(20)]\n",
    "zeros = [random.uniform(-3, 6) for i in range(20)]\n",
    "X = ones + zeros\n",
    "Y = np.hstack((np.ones(20, dtype='i'), np.zeros(20, dtype='i')))\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こういったデータは，あるデータの予測値が0か1かの離散的な値を直接出力するより，ある特徴量Xがクラス1に属する確率をP(X)としてモデル化した方が良い． 確率が0.5より大きければ1に，そうでなければ0に分類できる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ある関数について，その出力値を有限範囲に収まるようにモデル化することは数学的に難しい．  \n",
    "ここでは確率関数を調整することで，出力値を常に0~1の間に収まるようにする．  \n",
    "そのために，オッズ比(odds ratio)とその対数が必要  \n",
    "ここでオッズ比とは，ある事象の起きる確率(P)とある事象が起きない確率(1-P)の比，つまり$ \\frac{P}{P-1}$のこと．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば，ある特徴量について，それがクラス1に属する確率が0.9の場合，つまりP(y=1) = 0.9の場合を考える．  \n",
    "この時オッズ比は$\\frac{0.9}{0.1} = 9$これは，この特量量を持つデータが9:1の可能性でクラス1に属すると言える．  \n",
    "もしP(y=0.5)ならば，1:1の可能性になる．オッズ比が取りうる値の範囲は0~∞になる．  \n",
    "今ここでこのオッズ比について対数をとると，確率値が0~1をとる場合，それを-∞~+∞の範囲に変換できる．  \n",
    "この良い点としては，確率値が大きくなるにしたがい，その対数の値も大きくなるという関連性が保たれているということ．  \n",
    "そして，この逆数をとると，それは[-∞, ∞] -> [0, 1]の有限範囲を出力する関数になる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オッズ比のグラフ\n",
    "P = np.arange(0, 1, 0.01)\n",
    "odds = P / (1 - P)\n",
    "plt.plot(P, odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オッズの対数をとる関数\n",
    "import math\n",
    "logodds = [math.log(o) for o in odds[1:]] # log2(0)はエラー\n",
    "plt.plot(P[1:], logodds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オッズ比の対数関数の逆関数\n",
    "# 入力を無限の範囲に取り，0~1の値を出力する関数にできる\n",
    "plt.plot(logodds, P[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは，特徴量がXの1次元のみなので，これについて特徴量の線形な組み合わせの方程式をまず書いてみる\n",
    "$$ y_i = c_0 + c_1 x_i $$\n",
    "この$y_i$を$\\log(odds)$に置き換えると\n",
    "$$ \\log \\Bigr( \\frac{p_i}{1 - p_i} \\Bigl) = c_0 + c_1 x_i $$\n",
    "さらに，$p_i$について解を求める\n",
    "$$ \\frac{p_i}{1 - p_i} = \\exp(c_0 + c_1 x_i) $$\n",
    "$$ p_i = \\exp(c_0 + c_1 x_i) - \\exp(c_0 + c_1 x_i) p_i $$\n",
    "$$ ( 1 + \\exp(c_0 + c_1 x_i) )p_i = \\exp(c_0 + c_1 x_i) $$\n",
    "$$ p_i = \\frac{ \\exp(c_0 + c_1 x_i) }{ 1 + \\exp(c_0 + c_1 x_i) }$$\n",
    "$$ p_i = \\frac{ 1 }{ 1 + e^{-(c_0 + c_1 x_i)} }$$\n",
    "この得られた$p_i$の$c_0, c_1$を，全てのペアデータ($x_i$, $p_i$)に対して誤差が最小になるように最適化する．  \n",
    "これがロジスティック回帰である．  \n",
    "が，式の形から見てわかるように，結局はシグモイド関数である．  \n",
    "シグモイド関数の入力に渡す値の重みを調整し，白か黒かの確率を出力することとこのロジスティック回帰は等価である．  \n",
    "sklearnによってこの最適化作業を簡単に行うことができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs') # Specifyしないとワーニング吐かれる\n",
    "print(clf)\n",
    "\n",
    "clf.fit(np.array(X).reshape(-1, 1), Y)\n",
    "print(\"parameters:\", np.exp(clf.intercept_), np.exp(clf.coef_.ravel())) # intercept_: c0, coef_.ravel(): c1 ~ の係数\n",
    "\n",
    "def lr_model(clf, X):\n",
    "    return 1 / (1 + np.exp(-(clf.intercept_ + clf.coef_ * X)))\n",
    "\n",
    "print(\"P(x=-1)=%.2f\\tP(x=7)=%.2f\" % (lr_model(clf, -1), lr_model(clf, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y)\n",
    "P = np.arange(-5, 20, 0.01)\n",
    "plt.plot(P, [lr_model(clf, i).flatten() for i in P])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そしてこのようにして，フィッティングを行なったモデルをグラフに描画することで，データにうまく適合できていることがわかる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰を今回の問題に適用する\n",
    "ロジスティック回帰を用いた場合の正解率は，90NNの時とあまり変わらない．  \n",
    "ここで，ロジスティック回帰のパラメータとしてCがあるが，これはロジスティック回帰で正規化を行うためのパラメータである．  \n",
    "これを小さくするとモデルは複雑に，大きくするとモデルは単純になる．kNNのkと同じ役割を持つ．  \n",
    "<br>\n",
    "C=0.1の時が一番正解率が高いので，このモデルのバイアス-バリアンスについて見てみると，バイアスが大きいことがわかる．  \n",
    "テスト誤差と訓練誤差を示す線はデータが増えるごとに互いに近づいていくが，共にError=0.4と大きな値を取っている．  \n",
    "このことから，現在の特徴量に対するロジスティック回帰は未学習であり，データを正しく捉えることができていないと言える，  \n",
    "<br>\n",
    "バイアスが大きい原因は，\n",
    "- データにノイズが含まれすぎている\n",
    "- 設計した特徴量に問題がある\n",
    "\n",
    "が挙げられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 適合率と再現率\n",
    "我々は，分類器の評価を行うために，正解率を指標として用いてきたが，実際には回答の良し悪しを完璧に予測する必要はない．  \n",
    "たとえば，悪い回答であるかどうか，ということだけを分類した方が良い結果が出るかもしれない．  \n",
    "ここで，適合率と再現率について理解したい．  \n",
    "\n",
    "|事実|分類器の予測|結果|\n",
    "|:-:|:-:|:--|\n",
    "|陽|陽|True positive(TP)|\n",
    "|陽|陰|False positive(FP)|\n",
    "|陰|陽|False negative(TN)|\n",
    "|陰|陰|True negative(FN)|\n",
    "\n",
    "Trueとついているのが正しいところ，Falseとついているのが間違っているところ  \n",
    "positiveとついているのが予測結果が陽，negativeとついているのが予測結果が陰  \n",
    "<br>\n",
    "分類器が「Positive」と予測した中で，それが正しい割合を計算したものを「適合率(Precision)」と呼ぶ．  \n",
    "$$ Precision = \\frac{TP}{TP + FP} $$\n",
    "良い回答であると分類された回答の中で実際に良い回答であったものの割合にあたる．  \n",
    "<br>\n",
    "一方，事実が「Positive」であるものの中で，予測が正しかったものの割合を「再現率(Recall)」と呼ぶ．\n",
    "$$ Recall = \\frac{TP}{TP + FN} $$\n",
    "全ての良い回答の中で，良い回答と分類されたものの割合にあたる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適合率と再現率のより直感的な説明\n",
    "<br>\n",
    "システムA：  \n",
    "検索結果として50件ヒットした。すべてが犬の写真で誤りは1つもなかった。でも、データ群の中には取りこぼした犬の写真が70件あった。  \n",
    "<br>\n",
    "システムB：  \n",
    "検索結果として200件ヒットした。そのうち、80件は誤りだったけど、データ群の中の犬の写真はすべて拾い出した。取りこぼしは0件だった。  \n",
    "<br>\n",
    "どちらが優れているかは、その検索の目的によって異なる。  \n",
    "システムAは適合率 precision が高い。（適合率 1.0、再現率 0.41） -> 少しでも犬じゃないっぽいやつは取り除く， 間違わないが取りこぼす  \n",
    "システムBは再現率 recall が高い。（適合率 0.6、再現率 1.0） -> 少しでも犬っぽいなら取り込む， 取りこぼさないが間違う  \n",
    "<br>\n",
    "犯人を逃がすことがあるが冤罪は起こさない確率 -> 適合率  \n",
    "冤罪を起こすことがあっても犯人は捕まえる確率 -> 再現率  \n",
    "<br>\n",
    "このことからわかるように，適合率と再現率は基本的にトレードオフの関係にある．  \n",
    "再現率をあげても適合率が下がらないようなシステムが優秀であると言える．  \n",
    "つまり，犯人をとりこぼさず，かつ冤罪を起こさない警察こそが有能ということ．  \n",
    "この再現率を横軸，適合率を縦軸に取ったグラフがPrecision-Recall Curve．  \n",
    "適合率が上がっても(右に行っても)再現率が高い(曲線が上)ようなシステムが良く分類を行えていると言える．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適合率を最適にする方法を考える．  \n",
    "今のところ，閾値に$p_i = 0.5$という値を用いて回答の良し悪しを判定しているが，これを変更した時の，TP, FP, FNの数を数える．  \n",
    "それらの値から，再現率と適合率の変移をプロットする．  \n",
    "sklearnのmetricsモジュールのprecision_recall_curve関数によって，適合率と再現率の計算を行う．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "片方のクラス(例えば良い回答)を許容できる制度で分類できたとしても，もう片方のクラスを同じように許容できる制度で分類できるとは限らない．  \n",
    "良い回答と悪い回答でそれぞれ適合率-再現率曲線(Precision-Recall curve)を書いてみる．  \n",
    "これらのグラフの曲線下面積（Area Under the Curve)の値が直感的には分類器の平均的な適合率となる．  \n",
    "良い回答のAUCが0.7程度，悪い回答のAUCが0.62程度なので，良い回答かどうかを判別させた方が良い結果になることがわかる．  \n",
    "良い回答のAUCは，再現率が0.6程度に上がるまで適合率が0.8を超えており，良い感じである．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = np.argsort(scores)[len(scores) / 2]\n",
    "thresholds = np.hstack(([0], thresholds[medium]))\n",
    "idx80 = precisions >= 0.8\n",
    "print(\"P=%.2f R=%.2f thresh=%.2f\" % (precision[idx80][0], recall[idx80][0], threshold[idx80][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果，閾値を0．63に設定すると適合率が80％を超え，その時の再現率は37％であることがわかった．  \n",
    "これが意味することは，実際に良い回答の1/3に対してだけ判定を下すが，予測結果の8割以上は正しい結果であるということ．  \n",
    "分類器が予測を行うときにこの閾値（0．63）を適用するためには，predict_proba()メソッドを使う．  \n",
    "predict()メソッドは各データが属するクラスを返すが，predict_proba()は各データがそれぞれのクラスに属する確率を返す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh80 = threshold[idx80][0]\n",
    "probs_for_good = clf.predict_proba(answer_features)[:, 1]\n",
    "answer_class = probs_for_good > thresh80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_reportというモジュールで適合率と再現率の値を確認することができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.predit_proba[:, 1] > 0.63, target_names=['not accepted', 'accepted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでは適切な閾値を求めてきたが，その閾値を用いることで，必ず期待している適合率と再現率を満たすとは限らない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類器をスリムにする\n",
    "各特徴量が分類を行うためにどれだけ貢献しているか，は回帰係数の値で調べられる．  \n",
    "clf.coef_によって取得できる回帰係数が，大きいほど重要な特徴量である．  \n",
    "マイナスの値を持つ回帰係数は「悪い」と分類するときにおける影響が大きくなる．  \n",
    "これを調べてみると，LinkCountとNumExclamsがもっとも大きな影響力を持つことがわかる．  \n",
    "一方，回答中の画像の数は回帰係数が0に近いため，使わなくても分類器の性能にはほとんど影響を及ぼさない．  \n",
    "こういった特徴量は取り除くことができる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完成!\n",
    "この分類器をWebサイトに組み込むに当たって，アクセスがあるたびに分類器の訓練は行わず，訓練を行なった結果をシリアライズして，サイト上でデシリアライズすることで分類を素早く行う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open(\"logreg.dat\", \"w\")) # 書き込み\n",
    "clf = pickle.load(open(\"logreg.dat\", \"r\")) # 読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "ノイズが多く含まれるデータセットから，良い回答か悪い回答かの判別を部分的に達成した．  \n",
    "その過程で，最近傍法とロジスティック回帰の利点，欠点を学ぶことができた．  \n",
    "また，特徴量の抽出方法を学んだ．  \n",
    "それぞれの特徴量が分類器の性能にどれだけの影響があるかということを学んだ．  \n",
    "もっとも重要なのは，分類器の改善法．  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
